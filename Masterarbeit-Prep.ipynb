{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86b2fc4-9e4a-4be4-9b51-697acddfae07",
   "metadata": {},
   "source": [
    "# Prototyping model2regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50ce0f4-f4c7-4958-a082-2b4ba38ac0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c72da-1e5c-4aae-9b29-878d22f52292",
   "metadata": {},
   "source": [
    "Let's start by making a simple DGA:\n",
    "\n",
    "Rules:\n",
    "* always ends in .net\n",
    "* a is followed by random number of digits of length 10-20\n",
    "* seed is day of the month\n",
    "* the simple regex for this would be\n",
    "  ```py\n",
    "  r\"a[0-9]{10,20}\"\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d5d303-b6ae-4d88-af79-8d741a614633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a015034044502969.net', 'a4940242808385971.net', 'a952678823010460941.net', 'a178329295236.net', 'a7012476869089974329.net']\n"
     ]
    }
   ],
   "source": [
    "from random import Random\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from itertools import chain\n",
    "import torch.nn.functional as F\n",
    "rand = Random(str(datetime.today().day))\n",
    "def simple_dga():\n",
    "    digits = '0123456789'\n",
    "    return 'a' + ''.join(rand.choice(digits) for _ in range(rand.randint(10, 20))) + '.net'\n",
    "\n",
    "domains = []\n",
    "for i in range(1000):\n",
    "    domains.append(simple_dga())\n",
    "print(rand.choices(domains, k=5))\n",
    "\n",
    "class Domains(Dataset):\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.data = [simple_dga() for _ in range(size)]\n",
    "        self.chars = sorted(list(set(chain(*self.data))))\n",
    "        self.max_size = len(max(self.data, key=lambda d: len(d)))\n",
    "        self.char2ind = {ch : i for i,ch in enumerate(self.chars, start=1)}\n",
    "        self.ind2char = {i : ch for i,ch in enumerate(self.chars, start=1)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        item = torch.tensor([self.char2ind[c] for c in self.data[idx]])\n",
    "        item = F.pad(item, (0,self.max_size - len(item)), \"constant\", 0)\n",
    "        return (item, item[1:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cfb856-b22e-4cdd-8229-d71e6b96677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "x:\n",
      "\t tensor([[12,  8,  5,  ..., 15,  0,  0],\n",
      "        [12, 10, 10,  ..., 14, 13, 15],\n",
      "        [12, 10,  5,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [12,  5,  4,  ...,  0,  0,  0],\n",
      "        [12,  4,  8,  ...,  0,  0,  0],\n",
      "        [12,  4,  2,  ..., 15,  0,  0]]) torch.Size([64, 25])\n",
      "y:\n",
      "\t tensor([[ 8,  5,  9,  ..., 15,  0,  0],\n",
      "        [10, 10,  9,  ..., 14, 13, 15],\n",
      "        [10,  5,  7,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 5,  4, 10,  ...,  0,  0,  0],\n",
      "        [ 4,  8,  4,  ...,  0,  0,  0],\n",
      "        [ 4,  2,  9,  ..., 15,  0,  0]]) torch.Size([64, 24])\n",
      "1\n",
      "x:\n",
      "\t tensor([[12, 11, 11,  ...,  0,  0,  0],\n",
      "        [12,  3, 11,  ..., 14, 13, 15],\n",
      "        [12, 11,  6,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [12,  8,  8,  ...,  0,  0,  0],\n",
      "        [12, 11, 11,  ...,  0,  0,  0],\n",
      "        [12,  8,  6,  ..., 14, 13, 15]]) torch.Size([64, 25])\n",
      "y:\n",
      "\t tensor([[11, 11,  5,  ...,  0,  0,  0],\n",
      "        [ 3, 11,  4,  ..., 14, 13, 15],\n",
      "        [11,  6, 10,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 8,  8,  3,  ...,  0,  0,  0],\n",
      "        [11, 11,  5,  ...,  0,  0,  0],\n",
      "        [ 8,  6,  9,  ..., 14, 13, 15]]) torch.Size([64, 24])\n",
      "2\n",
      "x:\n",
      "\t tensor([[12,  2,  8,  ...,  0,  0,  0],\n",
      "        [12,  6,  9,  ...,  0,  0,  0],\n",
      "        [12,  3,  2,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [12, 11,  2,  ...,  0,  0,  0],\n",
      "        [12, 11,  5,  ..., 13, 15,  0],\n",
      "        [12,  6,  4,  ...,  0,  0,  0]]) torch.Size([64, 25])\n",
      "y:\n",
      "\t tensor([[ 2,  8,  7,  ...,  0,  0,  0],\n",
      "        [ 6,  9,  9,  ...,  0,  0,  0],\n",
      "        [ 3,  2,  3,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [11,  2,  7,  ...,  0,  0,  0],\n",
      "        [11,  5,  2,  ..., 13, 15,  0],\n",
      "        [ 6,  4,  7,  ...,  0,  0,  0]]) torch.Size([64, 24])\n",
      "3\n",
      "x:\n",
      "\t tensor([[12,  8,  2,  ...,  0,  0,  0],\n",
      "        [12, 11,  8,  ..., 14, 13, 15],\n",
      "        [12,  6,  6,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [12,  8,  3,  ...,  0,  0,  0],\n",
      "        [12,  5,  2,  ...,  0,  0,  0],\n",
      "        [12,  7, 10,  ...,  0,  0,  0]]) torch.Size([64, 25])\n",
      "y:\n",
      "\t tensor([[ 8,  2,  5,  ...,  0,  0,  0],\n",
      "        [11,  8,  5,  ..., 14, 13, 15],\n",
      "        [ 6,  6,  4,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 8,  3,  4,  ...,  0,  0,  0],\n",
      "        [ 5,  2,  2,  ...,  0,  0,  0],\n",
      "        [ 7, 10,  3,  ...,  0,  0,  0]]) torch.Size([64, 24])\n",
      "4\n",
      "x:\n",
      "\t tensor([[12,  7,  8,  ...,  0,  0,  0],\n",
      "        [12,  6,  5,  ..., 14, 13, 15],\n",
      "        [12,  7,  7,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [12, 10,  7,  ..., 14, 13, 15],\n",
      "        [12,  5,  7,  ..., 13, 15,  0],\n",
      "        [12,  5,  8,  ...,  0,  0,  0]]) torch.Size([64, 25])\n",
      "y:\n",
      "\t tensor([[ 7,  8, 11,  ...,  0,  0,  0],\n",
      "        [ 6,  5,  7,  ..., 14, 13, 15],\n",
      "        [ 7,  7,  4,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [10,  7,  3,  ..., 14, 13, 15],\n",
      "        [ 5,  7,  6,  ..., 13, 15,  0],\n",
      "        [ 5,  8,  8,  ...,  0,  0,  0]]) torch.Size([64, 24])\n",
      "5\n",
      "x:\n",
      "\t tensor([[12, 10,  6,  ..., 14, 13, 15],\n",
      "        [12,  9,  3,  ...,  0,  0,  0],\n",
      "        [12,  9,  4,  ..., 13, 15,  0],\n",
      "        ...,\n",
      "        [12,  2,  3,  ..., 15,  0,  0],\n",
      "        [12,  9,  4,  ...,  0,  0,  0],\n",
      "        [12,  7, 10,  ...,  0,  0,  0]]) torch.Size([64, 25])\n",
      "y:\n",
      "\t tensor([[10,  6,  5,  ..., 14, 13, 15],\n",
      "        [ 9,  3,  7,  ...,  0,  0,  0],\n",
      "        [ 9,  4, 11,  ..., 13, 15,  0],\n",
      "        ...,\n",
      "        [ 2,  3,  3,  ..., 15,  0,  0],\n",
      "        [ 9,  4,  7,  ...,  0,  0,  0],\n",
      "        [ 7, 10,  7,  ...,  0,  0,  0]]) torch.Size([64, 24])\n",
      "6\n",
      "x:\n",
      "\t tensor([[12,  7,  7,  ...,  0,  0,  0],\n",
      "        [12,  4, 10,  ..., 13, 15,  0],\n",
      "        [12,  3,  5,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [12,  9,  3,  ...,  0,  0,  0],\n",
      "        [12,  3, 10,  ...,  0,  0,  0],\n",
      "        [12,  9, 10,  ...,  0,  0,  0]]) torch.Size([64, 25])\n",
      "y:\n",
      "\t tensor([[ 7,  7,  2,  ...,  0,  0,  0],\n",
      "        [ 4, 10,  7,  ..., 13, 15,  0],\n",
      "        [ 3,  5,  6,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 9,  3,  5,  ...,  0,  0,  0],\n",
      "        [ 3, 10,  5,  ...,  0,  0,  0],\n",
      "        [ 9, 10,  8,  ...,  0,  0,  0]]) torch.Size([64, 24])\n"
     ]
    }
   ],
   "source": [
    "dataset = Domains(10000)\n",
    "for batch, (x,y) in enumerate(DataLoader(dataset, batch_size=64, shuffle=True)):\n",
    "    print(batch)\n",
    "    print(\"x:\\n\\t\", x, x.shape)\n",
    "    print(\"y:\\n\\t\", y, y.shape)\n",
    "    if batch > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ccabce-775e-4770-86fe-d9257bb04048",
   "metadata": {},
   "source": [
    "Next we want to use the example model from the talk.pdf page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a4b16d-4f65-44db-bf50-0264eac98858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocabSize, emb, size, nlayers):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocabSize,\n",
    "                                      embedding_dim=emb)\n",
    "        self.rnn = nn.GRU(input_size=emb, hidden_size=size,\n",
    "                          num_layers=nlayers)\n",
    "        self.decoder = nn.Linear(size, vocabSize)\n",
    "        \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        embedding = self.embedding(input_seq)\n",
    "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        return output, hidden_state.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412833a-ebb0-4c97-b9ee-b678cf5955cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7851b067-aa94-459b-bc04-a5f9b533a103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'.': 0,\n",
       "  'a': 1,\n",
       "  'n': 2,\n",
       "  't': 3,\n",
       "  '4': 4,\n",
       "  '7': 5,\n",
       "  '6': 6,\n",
       "  '3': 7,\n",
       "  '5': 8,\n",
       "  '9': 9,\n",
       "  '8': 10,\n",
       "  'e': 11,\n",
       "  '1': 12,\n",
       "  '2': 13,\n",
       "  '0': 14},\n",
       " {0: '.',\n",
       "  1: 'a',\n",
       "  2: 'n',\n",
       "  3: 't',\n",
       "  4: '4',\n",
       "  5: '7',\n",
       "  6: '6',\n",
       "  7: '3',\n",
       "  8: '5',\n",
       "  9: '9',\n",
       "  10: '8',\n",
       "  11: 'e',\n",
       "  12: '1',\n",
       "  13: '2',\n",
       "  14: '0'},\n",
       " {'.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'e', 'n', 't'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(domains[0])\n",
    "vocab = set()\n",
    "for domain in domains:\n",
    "    vocab = vocab.union(set(domain))\n",
    "c_to_ix = {c:i for i,c in enumerate(vocab)}\n",
    "ix_to_c = {i:c for i,c in enumerate(vocab)}\n",
    "c_to_ix, ix_to_c, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ad5de1-ccd6-49ed-9400-6ea2f6e96715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12,  7,  3,  ..., 15,  0,  0],\n",
      "        [12,  6,  2,  ...,  0,  0,  0],\n",
      "        [12,  7,  8,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [12,  7, 11,  ..., 15,  0,  0],\n",
      "        [12,  3,  7,  ..., 14, 13, 15],\n",
      "        [12,  8,  7,  ...,  0,  0,  0]]) torch.Size([64, 25])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(x, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m output, h0 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m), y)\n\u001b[0;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\Projects\\Masterarbeit\\pytorch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, input_seq, hidden_state)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_seq, hidden_state):\n\u001b[1;32m---> 12\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     output, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(embedding, hidden_state)\n\u001b[0;32m     14\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n",
      "File \u001b[1;32m~\\Projects\\Masterarbeit\\pytorch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Projects\\Masterarbeit\\pytorch\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Projects\\Masterarbeit\\pytorch\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "NLAYERS = 16\n",
    "EMBEDDING_DIM = 64\n",
    "losses = []\n",
    "def make_word_vector(domain):\n",
    "    idxs = [c_to_ix[c] for c in domain]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "h0 = torch.zeros((NLAYERS, HIDDEN_SIZE))\n",
    "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "dataset = Domains(10000)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "model = Model(len(dataset.chars),EMBEDDING_DIM, HIDDEN_SIZE, NLAYERS)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for batch, (x,y) in enumerate(dataloader):\n",
    "        print(x, x.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output, h0 = model(x, h0)\n",
    "        loss = criterion(output.permute(1,2,0), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print()\n",
    "    print(\"----------------------------------------------\")\n",
    "    print({'epoch': epoch, 'batch': batch, 'loss': loss.item()})\n",
    "    print(\"----------------------------------------------\")\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8211982-1aa5-41c6-934e-bd7a1b5612f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape, h0.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
