\documentclass[a4paper, 12pt]{article}

% Packages
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[backend=biber]{biblatex}
\usepackage{ifxetex}

% TUB Font
\ifxetex
   % Muli font
   \usepackage{xltxtra}
   \setmainfont{Muli}
\else
   % Arial font
   \usepackage{times}
   \renewcommand{\rmdefault}{\sfdefault}
\fi
\linespread{1.2}

% Settings
\graphicspath{ {images/} }
\addbibresource{bibliography.bib}

% Variables
\newcommand{\thesistitle}{model2regex: Detecting DGAs with Regular Expressions Generated by a Language Model}
\newcommand{\thesisauthor}{Eric Schneider}
\newcommand{\matrno}{365800}
\newcommand{\supervisor}{Alexander \textsc{Warnecke}, Tammo \textsc{Kr\"uger}}

\begin{document}

\begin{titlepage}
	\centering
	\includegraphics[width=5cm]{tub-logo}\par\vspace{0.5cm}
	{Technische Universität Berlin \par}
	\vspace{2cm}
	{\large \textsc{Exposé}\par}
	\vspace{1cm}
	{\Large\bfseries \thesistitle\par}
	\vspace{2cm}
	%\vfill
	{\large \thesisauthor\par}
	{\large Matr. No. \matrno\par}
	\vspace{2cm}
	\includegraphics[width=5cm]{mlsec-logo-red2}\par\vspace{0.5cm}
	{Chair of Machine Learning and Security \par}
	{Prof. Dr. Konrad Rieck \par}
	\vfill
	supervised by\par
	\supervisor
	\vfill
	\today\par
\end{titlepage}

\section{Introduction}
%Some intro to the topic: What is it about? What is the specific problem that should be addressed in this work?
Domain Generating Algorithms (DGAs) are increasingly used in botnets as part of
command and control (C\&C) communication. Malware creators use these algorithms
to generate multiple possible domains each day and then have their malware
contact a small portion of them to obfuscate the real server they are getting
their instructions and updates from. This tactic gives the attacker a huge
advantage, because to protect against it, means taking control of possible thousands
of domains, while the attacker only needs to control a short lived domain
executing their attack. Better protection may come from blocking
botnets at the source by recognizing communication with specific domains as
fraudulent or rather generated by a specific DGA family. DGAs however are
generated randomly and use different seeds from either specific dates, twitter
trends, hashes or word lists. Therefore static blocklists may not be able to
keep up with blocking the communication at a network level. Deep Learning
approaches have shown great promises and are currently state of the art in
detecting Algorithmically-Generated Domains (AGD). 
Machine learned models can be used to filter network traffic, but there are not simple setups to put
them into the filter pipeline, also is it difficult to know what the model exactly is filtering.
This thesis will therefore trying to attempt to use the help of deep learning approaches  to learn the structure
of domains generated by a DGA and use this information to then generate a regular expression (RegEx) 
which will match possible domains of that DGA. That approach could potential solve the two problems
of understanding what the structure the model sees and make the setup for filters much easier by
providing a standard way to set up a filter with a RegEx.


\section{Methodology}
%What methodology will be applied in this work? That is, what is the general
% strategy to solve the problem this work is concearned with?
The main methodology of this thesis will be applied research. Using currently established solutions
from the field of language processing. As data source of the learning process is a mix of real
domains \cite{noauthor_cisco_nodate} from domain lists and self-generated domains using reverse
engineered DGAs. \cite{bader_baderjdomain_generation_algorithms_2024} The main focus of the research
will be answering the two main questions. First, is it possible to generate Regular Expressions in
this setting? Second, do these regular expressions perform as well as the current state of the art?


\section{Approach}
%How is the implementation of the strategy approached?
I plan to split this thesis into three phases. First a research phase to expand on what I explored
during the development of the first prototype. I need to explore what methods for regular expression
generation can be used to extract them out of the RNN learned on the dataset. Also it should be part
of the research to figure out how to best simplify or make the resulting regular expressions more
efficient and capture the structure learned by the model. Currently the prototype is doing rather
well on the simple banjori algorithm during training. Once the possible approaches have been
explored I will need to implement them and do initial testing on how well they perform.  This may be
the biggest phase of the thesis work. After implementing the model and training it, I will need to
evaluate its performance and compare it to the state of the art.

\section{Evaluation}
%How is the degree of success of the applied method measured?
I will evaluate the result of this thesis by testing how well the generated regular expressions
will capture the learned structures of DGAs. I will compare how well these expressions will detect
AGDs. It is imperative that however the amount of false positives (benign domains detected as AGDs)
should be very low to not block valid connections with the generated filter.
The evaluation should compare how well the generated regular expression performs compared to the
language model and also how well it compares to other deep learning approaches shown in other
scientific papers. It should also be evaluated how well the language model and the regular
expression performs on different kinds of DGAs, or if it is only able to detect specific kinds. 
The degree of success should be measured through how close the solution is performing compared to
the state of the art \cite{yu_character_2018} and well established solutions in detection scores and false positive rates.

\section{Scope}
%What is the particular scope of your research? Which goals should be achieved?
%Which are optional and which are explicitly not part of the scope of this
%thesis?
The main scope of this work is determining the possibility of using the generated regular
expressions for
filtering and how well it works compared to trained models and the state of the art in the field for
Detecting DGAs. Part of the necessary work is training a multi-task criterion for the language model
and the classification of DGA and benign domains. If possible the resulting regular expressions
should be simplified to make them more readable and efficient, however this is not a necessary
requirement.

\section{Related Work}
%Describe the state of the art of the field of research. Support your statements
%with appropriate sources \cite{fardin14}.
The current state of the art in this field are hybrid solutions using convolutional and recurrent
neural networks. Two promising approaches were developed by Zhang \cite{zhang_detection_2019} and
Liu \cite{liu_detection_2020}, both utilizing SMOTE for balancing the datasets and both using the
hybrid solution of a bidirectional LSTM and a CNN. These approaches showed high accuracy and
f1-scores when detecting multiple DGA families at the same time, and experimented with different
text extraction techniques.
Rayhan \cite{rayhan_experimental_2020} also did a experimental analysis of 13 state-of-the-art
classification techniques. 

\clearpage

\printbibliography

\end{document}
