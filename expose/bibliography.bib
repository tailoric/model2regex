
@article{plohmann_comprehensive_nodate,
	title = {A {Comprehensive} {Measurement} {Study} of {Domain} {Generating} {Malware}},
	abstract = {Recent years have seen extensive adoption of domain generation algorithms (DGA) by modern botnets. The main goal is to generate a large number of domain names and then use a small subset for actual C\&C communication. This makes DGAs very compelling for botmasters to harden the infrastructure of their botnets and make it resilient to blacklisting and attacks such as takedown efforts. While early DGAs were used as a backup communication mechanism, several new botnets use them as their primary communication method, making it extremely important to study DGAs in detail.},
	language = {en},
	author = {Plohmann, Daniel and Yakdan, Khaled and Klatt, Michael and Gerhards-Padilla, Elmar and Bader, Johannes},
	file = {Plohmann et al. - A Comprehensive Measurement Study of Domain Genera.pdf:/home/eric/.zotero/zotero/15p3qvkc.default/zotero/storage/ZW74VEQF/Plohmann et al. - A Comprehensive Measurement Study of Domain Genera.pdf:application/pdf},
}

@inproceedings{drichel_false_2023,
	title = {False {Sense} of {Security}: {Leveraging} {XAI} to {Analyze} the {Reasoning} and {True} {Performance} of {Context}-less {DGA} {Classifiers}},
	shorttitle = {False {Sense} of {Security}},
	url = {http://arxiv.org/abs/2307.04358},
	doi = {10.1145/3607199.3607231},
	abstract = {The problem of revealing botnet activity through Domain Generation Algorithm (DGA) detection seems to be solved, considering that available deep learning classifiers achieve accuracies of over 99.9\%. However, these classifiers provide a false sense of security as they are heavily biased and allow for trivial detection bypass. In this work, we leverage explainable artificial intelligence (XAI) methods to analyze the reasoning of deep learning classifiers and to systematically reveal such biases. We show that eliminating these biases from DGA classifiers considerably deteriorates their performance. Nevertheless we are able to design a context-aware detection system that is free of the identified biases and maintains the detection rate of state-of-the art deep learning classifiers. In this context, we propose a visual analysis system that helps to better understand a classifierâ€™s reasoning, thereby increasing trust in and transparency of detection methods and facilitating decision-making.},
	language = {en},
	urldate = {2024-03-27},
	booktitle = {Proceedings of the 26th {International} {Symposium} on {Research} in {Attacks}, {Intrusions} and {Defenses}},
	author = {Drichel, Arthur and Meyer, Ulrike},
	month = oct,
	year = {2023},
	note = {arXiv:2307.04358 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	pages = {330--345},
	file = {Drichel and Meyer - 2023 - False Sense of Security Leveraging XAI to Analyze.pdf:/home/eric/.zotero/zotero/15p3qvkc.default/zotero/storage/VX4NY3K5/Drichel and Meyer - 2023 - False Sense of Security Leveraging XAI to Analyze.pdf:application/pdf},
}

@misc{bader_baderjdomain_generation_algorithms_2024,
	title = {Domain Generating Algorithms},
	copyright = {GPL-2.0},
	url = {https://github.com/baderj/domain_generation_algorithms},
	abstract = {Some results of my DGA reversing efforts},
	urldate = {2024-03-28},
	author = {Bader, Johannes},
	month = mar,
	year = {2024},
	note = {original-date: 2015-08-31T09:14:32Z},
	keywords = {dga, domain-generation-algorithm, malware, python, reverse-engineering},
}

@inproceedings{rudd_transformers_2022,
	title = {Transformers for {End}-to-{End} {InfoSec} {Tasks}: {A} {Feasibility} {Study}},
	shorttitle = {Transformers for {End}-to-{End} {InfoSec} {Tasks}},
	url = {http://arxiv.org/abs/2212.02666},
	doi = {10.1145/3494110.3528242},
	abstract = {In this paper, we assess the viability of transformer models in end-to-end InfoSec settings, in which no intermediate feature representations or processing steps occur outside the model. We implement transformer models for two distinct InfoSec data formats - specifically URLs and PE files - in a novel end-to-end approach, and explore a variety of architectural designs, training regimes, and experimental settings to determine the ingredients necessary for performant detection models. We show that in contrast to conventional transformers trained on more standard NLP-related tasks, our URL transformer model requires a different training approach to reach high performance levels. Specifically, we show that 1) pre-training on a massive corpus of unlabeled URL data for an auto-regressive task does not readily transfer to binary classification of malicious or benign URLs, but 2) that using an auxiliary auto-regressive loss improves performance when training from scratch. We introduce a method for mixed objective optimization, which dynamically balances contributions from both loss terms so that neither one of them dominates. We show that this method yields quantitative evaluation metrics comparable to that of several top-performing benchmark classifiers. Unlike URLs, binary executables contain longer and more distributed sequences of information-rich bytes. To accommodate such lengthy byte sequences, we introduce additional context length into the transformer by providing its self-attention layers with an adaptive span similar to Sukhbaatar et al. We demonstrate that this approach performs comparably to well-established malware detection models on benchmark PE file datasets, but also point out the need for further exploration into model improvements in scalability and compute efficiency.},
	urldate = {2024-03-30},
	booktitle = {Proceedings of the 1st {Workshop} on {Robust} {Malware} {Analysis}},
	author = {Rudd, Ethan M. and Rahman, Mohammad Saidur and Tully, Philip},
	month = may,
	year = {2022},
	note = {arXiv:2212.02666 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	pages = {21--31},
	file = {arXiv Fulltext PDF:/home/eric/.zotero/zotero/15p3qvkc.default/zotero/storage/AATQMH77/Rudd et al. - 2022 - Transformers for End-to-End InfoSec Tasks A Feasi.pdf:application/pdf;arXiv.org Snapshot:/home/eric/.zotero/zotero/15p3qvkc.default/zotero/storage/XYS9EPQ3/2212.html:text/html},
}

@inproceedings{yu_character_2018,
	title = {Character {Level} based {Detection} of {DGA} {Domain} {Names}},
	url = {https://ieeexplore.ieee.org/abstract/document/8489147},
	doi = {10.1109/IJCNN.2018.8489147},
	abstract = {Recently several different deep learning architectures have been proposed that take a string of characters as the raw input signal and automatically derive features for text classification. Few studies are available that compare the effectiveness of these approaches for character based text classification with each other. In this paper we perform such an empirical comparison for the important cybersecurity problem of DGA detection: classifying domain names as either benign vs. produced by malware (i.e., by a Domain Generation Algorithm). Training and evaluating on a dataset with 2M domain names shows that there is surprisingly little difference between various convolutional neural network (CNN) and recurrent neural network (RNN) based architectures in terms of accuracy, prompting a preference for the simpler architectures, since they are faster to train and to score, and less prone to overfitting.},
	urldate = {2024-03-30},
	booktitle = {2018 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Yu, Bin and Pan, Jie and Hu, Jiaming and Nascimento, Anderson and De Cock, Martine},
	month = jul,
	year = {2018},
	note = {ISSN: 2161-4407},
	keywords = {Computer architecture, cybersecurity, deep learning, domain generation algorithm, Feature extraction, Machine learning, malware, Malware, Recurrent neural networks, text classification, Training},
	pages = {1--8},
	file = {IEEE Xplore Abstract Record:/home/eric/.zotero/zotero/15p3qvkc.default/zotero/storage/T5NNDUBB/8489147.html:text/html},
}
